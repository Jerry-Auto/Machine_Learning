# PyTorch 模板项目  
PyTorch 深度学习项目开发标准化模板  

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->  

<!-- code_chunk_output -->  

- [PyTorch 模板项目](#pytorch-模板项目)
  - [系统要求](#系统要求)
  - [功能特性](#功能特性)
  - [目录结构](#目录结构)
  - [使用指南](#使用指南)
    - [配置文件格式](#配置文件格式)
    - [使用配置文件](#使用配置文件)
    - [从检查点恢复](#从检查点恢复)
    - [多GPU训练](#多gpu训练)
  - [自定义配置](#自定义配置)
    - [项目初始化](#项目初始化)
    - [自定义命令行参数](#自定义命令行参数)
    - [数据加载器](#数据加载器)
    - [训练器](#训练器)
    - [模型定义](#模型定义)
    - [损失函数](#损失函数)
    - [评估指标](#评估指标)
    - [附加日志](#附加日志)
    - [测试模型](#测试模型)
    - [验证数据](#验证数据)
    - [检查点](#检查点)
    - [TensorBoard可视化](#tensorboard可视化)
  - [贡献指南](#贡献指南)
  - [待办事项](#待办事项)
  - [许可证](#许可证)
  - [致谢](#致谢)

<!-- /code_chunk_output -->  

## 系统要求  
- Python >= 3.5（推荐3.6版本）  
- PyTorch >= 0.4（推荐1.2版本）  
- tqdm（运行test.py脚本时的可选依赖项）  
- tensorboard >= 1.14（详见[TensorBoard可视化](#tensorboard可视化)章节）  

## 功能特性  
- 采用清晰的目录结构设计，适配绝大多数深度学习项目开发需求  
- 支持.json格式配置文件，便于超参数调优与实验管理  
- 提供可扩展的命令行参数自定义功能  
- 完整的检查点（checkpoint）保存与恢复机制  
- 基于抽象基类的快速开发支持：  
  - BaseTrainer：封装检查点操作/训练日志/性能监控等基础功能  
  - BaseDataLoader：实现批次生成/数据洗牌/验证集划分等通用逻辑  
  - BaseModel：提供模型参数统计等基础方法  

## 目录结构  

pytorch-template/
│
├── train.py - 模型训练主入口脚本
├── test.py - 模型评估主入口脚本
│
├── config.json - 训练参数配置文件
├── parse_config.py - 配置解析与命令行参数处理模块
│
├── new_project.py - 项目初始化工具脚本
│
├── base/ - 抽象基类定义目录
│   ├── base_data_loader.py - 数据加载器基类
│   ├── base_model.py - 模型定义基类
│   └── base_trainer.py - 训练器基类
│
├── data_loader/ - 数据加载实现目录
│   └── data_loaders.py - 具体数据加载器实现
│
├── data/ - 默认数据集存储目录
│
├── model/ - 模型组件目录
│   ├── model.py - 核心模型实现
│   ├── metric.py - 评估指标实现
│   └── loss.py - 损失函数实现
│
├── saved/ - 持久化存储目录
│   ├── models/ - 训练模型检查点存储位置
│   └── log/ - 训练日志与TensorBoard数据目录
│
├── trainer/ - 训练流程实现目录
│   └── trainer.py - 具体训练逻辑实现
│
├── logger/ - 日志与可视化模块
│   ├── visualization.py - 可视化工具
│   ├── logger.py - 日志记录器
│   └── logger_config.json - 日志配置
│  
└── utils/ - 工具函数目录
    ├── util.py - 通用工具函数
    └── ... - 其他工具模块


## 使用指南  
本仓库以MNIST分类任务为例展示模板用法，执行`python train.py -c config.json`即可运行示例。  

### 配置文件格式  
配置文件采用标准JSON格式，完整结构如下：  
json
{
  "name": "Mnist_LeNet",        // 实验标识名称（用于区分不同训练会话）
  "n_gpu": 1,                   // 训练使用的GPU数量（0表示使用CPU）
  
  "arch": {                     // 模型架构配置组
    "type": "MnistModel",       // 模型类名称（需与代码中对应）
    "args": {}                  // 模型构造参数（留空表示使用默认参数）
  },
  "data_loader": {              // 数据加载配置组
    "type": "MnistDataLoader",  // 数据加载器类名称
    "args":{                    // 数据加载参数
      "data_dir": "data/",      // 数据集根目录路径
      "batch_size": 64,         // 训练批次大小
      "shuffle": true,          // 是否打乱训练数据顺序
      "validation_split": 0.1,  // 验证集划分比例（0.0-1.0）或绝对样本数
      "num_workers": 2          // 数据加载子进程数
    }
  },
  "optimizer": {                // 优化器配置组
    "type": "Adam",             // 优化器类型（需与torch.optim对应）
    "args":{                    // 优化器参数
      "lr": 0.001,              // 基础学习率
      "weight_decay": 0,        // L2正则化系数（可选）
      "amsgrad": true           // Adam优化器特有参数
    }
  },
  "loss": "nll_loss",           // 损失函数名称（需与代码实现对应）
  "metrics": [                  // 评估指标列表
    "accuracy",                 // 基础准确率
    "top_k_acc"                 // Top-k准确率
  ],                         
  "lr_scheduler": {             // 学习率调度器配置
    "type": "StepLR",           // 调度器类型
    "args":{                    // 调度器参数
      "step_size": 50,          // 学习率衰减周期（epoch数）
      "gamma": 0.1              // 衰减系数
    }
  },
  "trainer": {                  // 训练过程配置
    "epochs": 100,              // 最大训练轮次
    "save_dir": "saved/",       // 模型保存根目录
    "save_freq": 1,             // 检查点保存频率（每n个epoch保存一次）
    "verbosity": 2,             // 日志详细程度（0-静默 1-每epoch 2-完整日志）
  
    "monitor": "min val_loss",  // 模型监控模式（max/min 指标名，off表示禁用）
    "early_stop": 10,           // 早停机制等待轮次（0表示禁用）
  
    "tensorboard": true         // 是否启用TensorBoard可视化
  }
}


### 使用配置文件  
1. 修改config.json中的参数配置  
2. 执行训练命令：  
   bash
   python train.py --config config.json


### 从检查点恢复  
通过--resume参数指定检查点路径即可恢复训练：  
bash
python train.py --resume path/to/checkpoint


### 多GPU训练  
1. 配置文件中设置n_gpu参数指定GPU数量  
2. 通过--device参数指定GPU索引（如使用2号、3号GPU）：  
   bash
   python train.py --device 2,3 -c config.json

   等价于：  
   bash
   CUDA_VISIBLE_DEVICES=2,3 python train.py -c config.py


## 自定义配置  

### 项目初始化  
使用new_project.py快速创建新项目：  
bash
python new_project.py ../NewProject
  
该命令会创建包含所有模板文件的NewProject目录，自动过滤.gitignore文件和缓存文件。  

### 自定义命令行参数  
在parse_config.py中扩展CustomArgs配置：  
python
CustomArgs = collections.namedtuple('CustomArgs', 'flags type target')
options = [
    # 示例：添加学习率命令行参数
    CustomArgs(['--lr', '--learning_rate'], type=float, target=('optimizer', 'args', 'lr')),
    # 示例：添加批次大小命令行参数
    CustomArgs(['--bs', '--batch_size'], type=int, target=('data_loader', 'args', 'batch_size'))
]
  
此后可通过命令行直接覆盖配置参数：  
bash
python train.py -c config.json --bs 256 --lr 0.0001


### 数据加载器  
开发步骤：  
1. 继承BaseDataLoader基类（本质是torch.utils.data.DataLoader的扩展）  
2. 实现数据加载逻辑  

关键特性：  
- 自动批次生成  
- 内置数据洗牌功能  
- 通过split_validation()方法生成验证集加载器  

使用示例：  
python
for batch_idx, (x_batch, y_batch) in data_loader:
    # 训练代码...


完整示例参考data_loader/data_loaders.py中的MNIST实现。  

### 训练器  
开发步骤：  
1. 继承BaseTrainer基类  
2. 实现_train_epoch()抽象方法（必需）  
3. 可选实现_valid_epoch()方法（如需验证逻辑）  

核心功能：  
- 自动日志记录（支持多级别verbosity配置）  
- 检查点保存（支持常规保存与最佳模型保存）  
- 早停机制（通过monitor和early_stop参数配置）  
- 学习率调度器集成  

迭代式训练支持：  
通过Trainer.__init__的len_epoch参数控制每epoch的迭代次数。  

完整示例参考trainer/trainer.py。  

### 模型定义  
开发步骤：  
1. 继承BaseModel基类（本质是nn.Module的扩展）  
2. 实现forward()抽象方法  

增强功能：  
- 改进的__str__方法，自动统计可训练参数量  

完整示例参考model/model.py中的LeNet实现。  

### 损失函数  
实现规范：  
1. 在model/loss.py中实现自定义损失函数  
2. 在配置文件的"loss"字段指定对应名称  

### 评估指标  
实现规范：  
1. 在model/metric.py中实现指标函数  
2. 在配置文件的"metrics"数组中指定（支持多指标）：  
   json
   "metrics": ["accuracy", "top_k_acc"]


### 附加日志  
在训练器中扩展日志记录：  
python
def _train_epoch(self, epoch):
    # ...训练逻辑...
    log.update({"gradient_norm": g, "sensitivity": s})
    return log


### 测试模型  
使用test.py评估训练好的模型：  
bash
python test.py --resume path/to/checkpoint


### 验证数据  
通过BaseDataLoader.split_validation()获取验证集加载器：  
- validation_split支持比例（0.0-1.0）或绝对样本数  
- 设置为0时返回None  

注意：调用该方法会修改原始数据加载器的行为  

### 检查点  
存储规范：  
- 路径格式：save_dir/name/timestamp/  
- 文件名格式：checkpoint_epoch_{n}.pth  
- 自动保存配置文件副本  

检查点内容：  
python
{
    'arch': model_architecture,      # 模型架构信息
    'epoch': current_epoch,         # 当前训练轮次
    'state_dict': model_state,       # 模型参数
    'optimizer': optimizer_state,    # 优化器状态
    'monitor_best': best_metric,     # 最佳指标值
    'config': training_config       # 完整配置
}


### TensorBoard可视化  
配置步骤：  
1. 安装依赖：  
   bash
   pip install tensorboard>=1.14.0
  
2. 配置文件中启用：  
   json
   "tensorboard": true
  
3. 启动可视化服务：  
   bash
   tensorboard --logdir saved/log/
  

默认记录内容：  
- 损失函数曲线  
- 配置的评估指标  
- 输入样本可视化（如适用）  
- 模型参数分布直方图  

扩展记录：  
在_train_epoch()中使用add_scalar()/add_image()等方法添加自定义记录。  

## 贡献指南  
欢迎提交Pull Request，代码规范要求：  
- 严格遵循PEP8风格指南  
- 必须通过Flake8静态检查（提交前运行检查）  

## 待办事项  
- [ ] 多优化器支持（如GAN训练场景）  
- [ ] 增强TensorBoard功能集成  
- [x] 固定随机种子功能  
- [x] 原生PyTorch TensorBoard支持  
- [x] tensorboardX兼容支持  
- [x] 可配置的日志布局方案  
- [x] 基于迭代次数的训练模式  
- [x] 命令行微调参数支持  

## 许可证  
本项目采用MIT开源许可证，完整条款详见LICENSE文件。  

## 致谢  
本项目设计灵感来源于[Mahmoud Gemy](https://github.com/MrGemy95)开发的[Tensorflow-Project-Template](https://github.com/MrGemy95/Tensorflow-Project-Template)项目模板。